from sqlalchemy import create_engine
import pandas as pd
from sqlalchemy import create_engine

engine_ccd = create_engine('mysql+pymysql://root:xiannan@localhost:3306/ccd')
engine_gd = create_engine('mysql+pymysql://root:xiannan@localhost:3306/gd')



def MYB_read_and_concatenate(folder_path):
    all_dfs = []
    for filename in os.listdir(folder_path):
        if filename.endswith('.xls') or filename.endswith('.xlsx'):
            try:
                df = pd.read_excel(os.path.join(folder_path, filename), header=1)
                all_dfs.append(df)
                print(f"æˆåŠŸè¯»å– {filename}ã€‚")
            except Exception as e:
                print(f"è¯»å– {filename} æ—¶å‡ºé”™ï¼š{e}")
    if all_dfs:
        return pd.concat(all_dfs)
    else:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Excel æ–‡ä»¶ã€‚")
        return None

def commission(folder_path):
    all_dfs = []
    for filename in os.listdir(folder_path):
        if filename.endswith('.xls') or filename.endswith('.xlsx'):
            try:
                df = pd.read_excel(os.path.join(folder_path, filename), header=1,dtype={'è®¢å•å·': str,'è¿å•å·': str})
                df['æ¥æºæ–‡ä»¶'] = filename
                all_dfs.append(df)
                print(f"æˆåŠŸè¯»å– {filename}ã€‚")
            except Exception as e:
                print(f"è¯»å– {filename} æ—¶å‡ºé”™ï¼š{e}")
    if all_dfs:
        return pd.concat(all_dfs)
    else:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Excel æ–‡ä»¶ã€‚")
        return None




def MYB_read_and_concatenate_oil_0(folder_path):
    all_dfs = []

    # è·å–æ–‡ä»¶åˆ—è¡¨å¹¶æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
    files = [f for f in os.listdir(folder_path) if f.endswith('.xls') or f.endswith('.xlsx')]
    files = sorted(files, key=lambda x: os.path.getmtime(os.path.join(folder_path, x)))

    for filename in files:
        try:
            df = pd.read_excel(os.path.join(folder_path, filename), header=0, dtype={'å¹³å°å•å·': str})
            df['æ–‡ä»¶å'] = filename
            all_dfs.append(df)
            print(f"æˆåŠŸè¯»å– {filename}ã€‚")
        except Exception as e:
            print(f"è¯»å– {filename} æ—¶å‡ºé”™ï¼š{e}")

    if all_dfs:
        all = pd.concat(all_dfs, ignore_index=True)
        # all = all.astype(str)
        return all
    else:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Excel æ–‡ä»¶ã€‚")
        return None

def MYB_read_and_concatenate_oil(folder_path):
    all_dfs = []

    # è·å–æ–‡ä»¶åˆ—è¡¨å¹¶æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
    files = [f for f in os.listdir(folder_path) if f.endswith('.xls') or f.endswith('.xlsx')]
    files = sorted(files, key=lambda x: os.path.getmtime(os.path.join(folder_path, x)))

    for filename in files:
        try:
            df = pd.read_excel(os.path.join(folder_path, filename), header=1)
            df['æ–‡ä»¶å'] = filename
            all_dfs.append(df)
            print(f"æˆåŠŸè¯»å– {filename}ã€‚")
        except Exception as e:
            print(f"è¯»å– {filename} æ—¶å‡ºé”™ï¼š{e}")

    if all_dfs:
        return pd.concat(all_dfs, ignore_index=True)
    else:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Excel æ–‡ä»¶ã€‚")
        return None

def MYB_read_and_concatenate_2(folder_path):
    all_dfs = []
    for filename in os.listdir(folder_path):
        if filename.endswith('.xls') or filename.endswith('.xlsx'):
            try:
                # è¯»å– Excel æ–‡ä»¶çš„æ‰€æœ‰å·¥ä½œè¡¨
                xls = pd.ExcelFile(os.path.join(folder_path, filename))
                for sheet_name in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name, header=2)
                    all_dfs.append(df)
                    print(f"æˆåŠŸè¯»å– {filename} çš„ {sheet_name} å·¥ä½œè¡¨ã€‚")
            except Exception as e:
                print(f"è¯»å– {filename} æ—¶å‡ºé”™ï¼š{e}")
    if all_dfs:
        return pd.concat(all_dfs)
    else:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Excel æ–‡ä»¶ã€‚")
        return None


def MYB_read_and_concatenate_header(folder_path,header):
    all_dfs = []
    for filename in os.listdir(folder_path):
        if filename.endswith('.xls') or filename.endswith('.xlsx'):
            try:
                # è¯»å– Excel æ–‡ä»¶çš„æ‰€æœ‰å·¥ä½œè¡¨
                xls = pd.ExcelFile(os.path.join(folder_path, filename))
                for sheet_name in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name, header=header,dtype=str)
                    all_dfs.append(df)
                    print(f"æˆåŠŸè¯»å– {filename} çš„ {sheet_name} å·¥ä½œè¡¨ã€‚")
            except Exception as e:
                print(f"è¯»å– {filename} æ—¶å‡ºé”™ï¼š{e}")
    if all_dfs:
        return pd.concat(all_dfs)
    else:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Excel æ–‡ä»¶ã€‚")
        return None
def data_astype(data,indexes,type):
    for i in indexes:
        data[i] = data[i].astype(type)

def car_revnue():
    engine = create_engine('mysql+pymysql://root:xiannan@localhost:3306/ccd')
    df_car = pd.read_sql('SELECT å‘è¿å•å·, çœ, å¸‚, å¿åŒº, ç»“ç®—ç‚¹, è·ç¦», è¿è¾“è´¹ç”¨, æ²¹å¡è´¹ç”¨, æŒ‡å¯¼ä»·, æ‰¿æ‹…è¿è´¹ç±»å‹, æ‰¿æ‹…è¿è´¹, çº¿è·¯åç§°, è°ƒåº¦å‘˜, å¸è´§ç‚¹æ•°, ç®€è¦åœ°å€ FROM car',con=engine)
    data_astype(df_car,['è¿è¾“è´¹ç”¨','æ²¹å¡è´¹ç”¨','æ‰¿æ‹…è¿è´¹'],float)
    df_car['å‘è¿å•å·'] = df_car['å‘è¿å•å·'].str.replace('-1','')
    df_car = df_car.groupby(['å‘è¿å•å·']).agg({
        'ç»“ç®—ç‚¹':'first',
        'çœ':'first',
        'å¸‚':'first',
        'å¿åŒº':'first',
        'è·ç¦»':'first',
        'è¿è¾“è´¹ç”¨':'sum',
        'æ²¹å¡è´¹ç”¨':'sum',
        'æŒ‡å¯¼ä»·':'sum',
        'æ‰¿æ‹…è¿è´¹ç±»å‹':'first',
        'æ‰¿æ‹…è¿è´¹':'sum',
        'çº¿è·¯åç§°':'first',
        'è°ƒåº¦å‘˜':'first',
        'å¸è´§ç‚¹æ•°':'first'
    })
    df_revenue = pd.read_sql('SELECT * FROM revenue WHERE å‘è¿å•å· NOT LIKE "%%CCD%%"',con=engine)
    data_astype(df_revenue,['é‡‡è´­ä»·','ç»“ç®—ä»·'],float)
    df_revenue['å‘è¿å•å·'] = df_revenue['å‘è¿å•å·'].str.replace('-1','')
    df_revenue['ä¸šåŠ¡æ—¥æœŸ'] = pd.to_datetime(df_revenue['ä¸šåŠ¡æ—¥æœŸ'],format='%Y%m%d')
    df_revenue['å¹´'] = df_revenue['ä¸šåŠ¡æ—¥æœŸ'].dt.year
    df_revenue['æœˆ'] = df_revenue['ä¸šåŠ¡æ—¥æœŸ'].dt.month
    df_revenue['å­£'] = df_revenue['ä¸šåŠ¡æ—¥æœŸ'].dt.quarter
    df_merge = pd.merge(df_revenue,df_car,on='å‘è¿å•å·',how='left')
    df_merge['å¸æœºè¿è´¹'] = df_merge['è¿è¾“è´¹ç”¨'] + df_merge['æ²¹å¡è´¹ç”¨']
    df_merge.loc[df_merge['æ‰¿æ‹…è¿è´¹ç±»å‹'] == 'æ‰¿æ‹…è¿è´¹ç°ç»“', 'å¸æœºè¿è´¹'] = df_merge.loc[df_merge['æ‰¿æ‹…è¿è´¹ç±»å‹'] == 'æ‰¿æ‹…è¿è´¹ç°ç»“','å¸æœºè¿è´¹'] + df_merge.loc[df_merge['æ‰¿æ‹…è¿è´¹ç±»å‹'] == 'æ‰¿æ‹…è¿è´¹ç°ç»“', 'æ‰¿æ‹…è¿è´¹']
    df_merge.loc[df_merge['æ‰¿æ‹…è¿è´¹ç±»å‹'] == 'æ‰¿æ‹…è¿è´¹ç°ç»“', 'é‡‡è´­ä»·'] = df_merge.loc[df_merge[
                                                                                            'æ‰¿æ‹…è¿è´¹ç±»å‹'] == 'æ‰¿æ‹…è¿è´¹ç°ç»“', 'é‡‡è´­ä»·'] + \
                                                                           df_merge.loc[df_merge[
                                                                                            'æ‰¿æ‹…è¿è´¹ç±»å‹'] == 'æ‰¿æ‹…è¿è´¹ç°ç»“', 'æ‰¿æ‹…è¿è´¹']/1.09
    return df_merge

def car_revnue_tax():
    engine = create_engine('mysql+pymysql://root:xiannan@localhost:3306/ccd')
    df_car = pd.read_sql('SELECT å‘è¿å•å·, çœ, å¸‚, å¿åŒº, ç»“ç®—ç‚¹, è·ç¦», è¿è¾“è´¹ç”¨, å®é™…è¿è´¹, æ²¹å¡è´¹ç”¨, æˆæœ¬æ€»é‡‘é¢, æŒ‡å¯¼ä»·, æ‰¿æ‹…è¿è´¹ç±»å‹, æ‰¿æ‹…è¿è´¹, çº¿è·¯åç§°, è°ƒåº¦å‘˜, å¸è´§ç‚¹æ•°, ç®€è¦åœ°å€ FROM car',con=engine)
    data_astype(df_car,['è¿è¾“è´¹ç”¨','æ²¹å¡è´¹ç”¨','æ‰¿æ‹…è¿è´¹','æˆæœ¬æ€»é‡‘é¢'],float)
    df_car['å‘è¿å•å·'] = df_car['å‘è¿å•å·'].str.replace('-1','')
    df_car = df_car.groupby(['å‘è¿å•å·']).agg({
        'ç»“ç®—ç‚¹':'first',
        'çœ':'first',
        'å¸‚':'first',
        'å¿åŒº':'first',
        'è·ç¦»':'first',
        'è¿è¾“è´¹ç”¨':'sum',
        'æ²¹å¡è´¹ç”¨':'sum',
        'æŒ‡å¯¼ä»·':'sum',
        'æ‰¿æ‹…è¿è´¹ç±»å‹':'first',
        'æ‰¿æ‹…è¿è´¹':'sum',
        'çº¿è·¯åç§°':'first',
        'è°ƒåº¦å‘˜':'first',
        'å¸è´§ç‚¹æ•°':'first',
        'æˆæœ¬æ€»é‡‘é¢':'sum',
        'å®é™…è¿è´¹':'sum'
    })
    df_revenue = pd.read_sql('SELECT * FROM revenue WHERE å‘è¿å•å· NOT LIKE "%%CCD%%"',con=engine)
    df_revenue['ä¸šåŠ¡æ—¥æœŸ'] = pd.to_datetime(df_revenue['ä¸šåŠ¡æ—¥æœŸ'],format='%Y%m%d')
    df_revenue['å¹´'] = df_revenue['ä¸šåŠ¡æ—¥æœŸ'].dt.year
    df_revenue['æœˆ'] = df_revenue['ä¸šåŠ¡æ—¥æœŸ'].dt.month
    df_revenue['å­£'] = df_revenue['ä¸šåŠ¡æ—¥æœŸ'].dt.quarter
    df_merge = pd.merge(df_revenue,df_car,on='å‘è¿å•å·',how='left')
    df_merge.loc[df_merge['æ‰¿æ‹…è¿è´¹ç±»å‹'] == 'æ‰¿æ‹…è¿è´¹ç°ç»“', 'é‡‡è´­ä»·'] = df_merge.loc[df_merge[
                                                                                            'æ‰¿æ‹…è¿è´¹ç±»å‹'] == 'æ‰¿æ‹…è¿è´¹ç°ç»“', 'æˆæœ¬æ€»é‡‘é¢'] + \
                                                                           df_merge.loc[df_merge[
                                                                                            'æ‰¿æ‹…è¿è´¹ç±»å‹'] == 'æ‰¿æ‹…è¿è´¹ç°ç»“', 'æ‰¿æ‹…è¿è´¹']
    df_merge.loc[df_merge['æ‰¿æ‹…è¿è´¹ç±»å‹'] != 'æ‰¿æ‹…è¿è´¹ç°ç»“', 'é‡‡è´­ä»·'] = df_merge.loc[df_merge['æ‰¿æ‹…è¿è´¹ç±»å‹'] != 'æ‰¿æ‹…è¿è´¹ç°ç»“', 'æˆæœ¬æ€»é‡‘é¢']
    return df_merge

def match_2in_1out(row, dict,data1,data2):
    for a1, a2 in dict.items():
        for b1, b2 in a2.items():
            if row[data1] == b1 and row[data2] == b2:
                return a1
    return None

def extract_tonnage_from_remark(remark):
    match = re.search(r'(\d+(\.\d+)?)\s*T', remark)
    if match:
        return float(match.group(1))
    else:
        return None


def standardize_truck_size(size_str):
    size_str = size_str.replace("ç±³", "").strip()
    try:
        size = float(size_str)
    except ValueError:
        return "æœªçŸ¥"

    if size <= 5.5:
        return "4.2ç±³"
    elif size <= 8.2:
        return "6.8ç±³"
    elif size <= 11.1:
        return "9.6ç±³"
    elif size <= 15:
        return "12.5ç±³"
    elif size <= 20:
        return "17.5ç±³"
    else:
        return "æœªçŸ¥"
def get_quarter(business_date):
    quarter = (business_date.month - 1) // 3 + 1
    return quarter


import re

def extract_fund(text):
    if isinstance(text, float):
        return 0
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æœç´¢é‡‘é¢
    amounts = re.findall(r'(\d+å…ƒ)', str(text))

    # å¦‚æœæ‰¾åˆ°äº†é‡‘é¢
    if amounts:
        # æå–ç¬¬ä¸€ä¸ªé‡‘é¢
        amount = amounts[0]
        # åˆ¤æ–­ 'å…ƒ' å‰é¢æ˜¯å¦æœ‰æ•°å­—
        if text.split(amount)[0].isdigit():
            return amount
        else:
            # æå– 'åˆ°ä»˜' å‰é¢çš„æ•°å­—
            payment = re.search(r'(\d+)åˆ°ä»˜', text)
            if payment:
                return payment.group(1) + 'å…ƒ'
            else:
                return None
    else:
        return '0'

def multi(address) :
    amount = 1
    count_one = address.count('+')
    count_two = address.count('ã€')
    count_point_one = address.count('ä¸¤åœ°')
    count_point_two = address.count('ä¸‰åœ°')
    count_point_three = address.count('å››åœ°')
    amount = amount + count_one + count_two + count_point_one*2 + count_point_two*3 + count_point_three*4
    return amount


def find_closest_date(orders_df, price_adjustments_df):
    closest_dates = []
    for order_date in orders_df['ä¸šåŠ¡æ—¥æœŸ']:
        # ç­›é€‰å‡ºå°äºç­‰äºè®¢å•æ—¥æœŸçš„æœ€è¿‘æ—¥æœŸ
        closest_date_df = price_adjustments_df[price_adjustments_df['è°ƒæ•´æ—¥æœŸ'] <= order_date]
        if closest_date_df.empty:
            closest_dates.append({'è°ƒæ•´æ—¥æœŸ': 0, 'ç´¢å¼•': None})
        else:
            closest_date = closest_date_df.iloc[-1]
            closest_date_index = closest_date_df.index[-1]
            closest_dates.append({'è°ƒæ•´æ—¥æœŸ': closest_date, 'ç´¢å¼•': closest_date_index})
    return pd.DataFrame(closest_dates)


def guanxing(guan,zong):
    if guan == zong:
        return 'çº¯ç®¡é“'
    elif guan == 0:
        return 'çº¯å‹æ'
    else:
        return 'ç®¡å‹'

def plate_number(driver_info):
    parts = driver_info.split('/')
    if len(parts) > 2:
        return parts[2]
    else:
        return None

def plate_clean(plate):
    plate = plate.replace(' ','')
    plate = plate.replace('?','')
    return plate

def extract_chinese_characters(s):
    chinese_characters = re.findall(r'[\u4e00-\u9fff]+', s)
    return ''.join(chinese_characters)

def driver_region(plate):
    license_plate_mapping = {
        'äº¬': 'åŒ—äº¬å¸‚',
        'æ´¥': 'å¤©æ´¥å¸‚',
        'æ²ª': 'ä¸Šæµ·å¸‚',
        'æ¸': 'é‡åº†å¸‚',
        'å†€': 'æ²³åŒ—çœ',
        'æ™‹': 'å±±è¥¿çœ',
        'è¾½': 'è¾½å®çœ',
        'å‰': 'å‰æ—çœ',
        'é»‘': 'é»‘é¾™æ±Ÿçœ',
        'è‹': 'æ±Ÿè‹çœ',
        'æµ™': 'æµ™æ±Ÿçœ',
        'çš–': 'å®‰å¾½çœ',
        'é—½': 'ç¦å»ºçœ',
        'èµ£': 'æ±Ÿè¥¿çœ',
        'é²': 'å±±ä¸œçœ',
        'è±«': 'æ²³å—çœ',
        'é„‚': 'æ¹–åŒ—çœ',
        'æ¹˜': 'æ¹–å—çœ',
        'ç²¤': 'å¹¿ä¸œçœ',
        'ç¼': 'æµ·å—çœ',
        'å·': 'å››å·çœ',
        'è´µ': 'è´µå·çœ',
        'äº‘': 'äº‘å—çœ',
        'é™•': 'é™•è¥¿çœ',
        'ç”˜': 'ç”˜è‚ƒçœ',
        'é’': 'é’æµ·çœ',
        'è—': 'è¥¿è—è‡ªæ²»åŒº',
        'æ¡‚': 'å¹¿è¥¿å£®æ—è‡ªæ²»åŒº',
        'å®': 'å®å¤å›æ—è‡ªæ²»åŒº',
        'æ–°': 'æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº',
        'å°': 'å°æ¹¾çœ',
        'æ¸¯': 'é¦™æ¸¯ç‰¹åˆ«è¡Œæ”¿åŒº',
        'æ¾³': 'æ¾³é—¨ç‰¹åˆ«è¡Œæ”¿åŒº'
    }
    region = plate.str.slice(stop=1).map(license_plate_mapping)
    return region


import os
import pandas as pd

def inventory(address):
    """
    Reads all CSV and Excel files (including all sheets) from the specified directory
    and combines them into a single DataFrame.

    Parameters:
        address (str): The directory containing the CSV and Excel files.

    Returns:
        DataFrame: A combined DataFrame of all the files, or None if no files were found.
    """
    # Initialize an empty list to store the dataframes
    dataframes = []

    # Check if the directory exists
    if os.path.exists(address):
        # List all files in the directory
        file_list = os.listdir(address)

        if file_list:
            print("Files found in the directory:")
            for filename in file_list:
                print(filename)
                # Check if the file is a CSV or Excel file
                file_path = os.path.join(address, filename)
                if filename.endswith('.csv'):
                    df = pd.read_csv(file_path)
                    dataframes.append(df)
                elif filename.endswith('.xls') or filename.endswith('.xlsx'):
                    excel_data = pd.ExcelFile(file_path)
                    for sheet_name in excel_data.sheet_names:
                        df = pd.read_excel(file_path, sheet_name=sheet_name)
                        dataframes.append(df)

            # Combine all dataframes into one if there are any
            if dataframes:
                combined_df = pd.concat(dataframes, ignore_index=True)
                # Display the first few rows of the combined dataframe
                print("Combined DataFrame:")
                print(combined_df.head())
                return combined_df
            else:
                print("No CSV or Excel files found in the directory.")
                return None
        else:
            print("The directory is empty.")
            return None
    else:
        print("The directory does not exist.")
        return None


def trivil_read_and_concatenate_header(folder_path,header):
    all_dfs = []
    for filename in os.listdir(folder_path):
        if filename.endswith('.xls') or filename.endswith('.xlsx'):
            try:
                # è¯»å– Excel æ–‡ä»¶çš„æ‰€æœ‰å·¥ä½œè¡¨
                xls = pd.ExcelFile(os.path.join(folder_path, filename))
                for sheet_name in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name, header=header)
                    df['æ‰¿è¿å•†'] = sheet_name
                    all_dfs.append(df)
                    print(f"æˆåŠŸè¯»å– {filename} çš„ {sheet_name} å·¥ä½œè¡¨ã€‚")
            except Exception as e:
                print(f"è¯»å– {filename} æ—¶å‡ºé”™ï¼š{e}")
    if all_dfs:
        return pd.concat(all_dfs)
    else:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Excel æ–‡ä»¶ã€‚")
        return None

def cost_year(df_merge,year,car):
    df_merge = df_merge[df_merge['å¹´']==year]
    df_merge = df_merge[df_merge['è½¦å‹']==car]
    df_agg = df_merge.groupby(['ç»“ç®—ç‚¹','å…¬å¸']).agg(é‡‡è´­å‡ä»·=('é‡‡è´­ä»·','mean'),æ€»è½¦æ¬¡=('å‘è¿å•å·','count'),æ€»æˆæœ¬=('é‡‡è´­ä»·','sum')).reset_index()
    df_agg['é‡‡è´­å‡ä»·'] = df_agg['é‡‡è´­å‡ä»·'].round(0)
    df_agg.rename(columns={'é‡‡è´­å‡ä»·':f'{year}_{car}é‡‡è´­ä»·','æ€»è½¦æ¬¡':f'{year}_{car}è½¦æ¬¡','æ€»æˆæœ¬':f'{year}_{car}æ€»æˆæœ¬'},inplace=True)
    return df_agg

def start(df):
    base_address = {'å¹¿ä¸œè¥ä¸šéƒ¨': ('Y', 'å¹¿ä¸œçœ,èŒ‚åå¸‚,é«˜å·å¸‚'),
                    'ç¦å»ºè¥ä¸šéƒ¨': ('M', 'ç¦å»ºçœ,æ¼³å·å¸‚,æ¼³æµ¦å¿'),
                    'å‰æ—è¥ä¸šéƒ¨': ('L', 'å‰æ—çœ,é•¿æ˜¥å¸‚,ä¹å°åŒº'),
                    'æ–°ç–†è¥ä¸šéƒ¨': ('J', 'æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº,ä¹Œé²æœ¨é½å¸‚,æ²™ä¾å·´å…‹åŒº'),
                    'å››å·è¥ä¸šéƒ¨': ('D', 'å››å·çœ,æˆéƒ½å¸‚,é¾™æ³‰é©¿åŒº'),
                    'å¤©æ´¥è¥ä¸šéƒ¨': ('T', 'å¤©æ´¥å¸‚,å¤©æ´¥å¸‚,æ»¨æµ·æ–°åŒº'),
                    'æ¹–å—è¥ä¸šéƒ¨': ('H', 'æ¹–å—çœ,é•¿æ²™å¸‚,å®ä¹¡å¸‚'),
                    'å…­å®‰è¥ä¸šéƒ¨': ('W', 'å®‰å¾½çœ,å…­å®‰å¸‚,é‡‘å®‰åŒº'),
                    'ä¸‹æ²™è¥ä¸šéƒ¨': ('S', 'æµ™æ±Ÿçœ,æ­å·å¸‚,é’±å¡˜åŒº'),
                    'è¥¿å®‰è¥ä¸šéƒ¨': ('A', 'é™•è¥¿çœ,è¥¿å®‰å¸‚,é›å¡”åŒº'),
                    'æ–°æ˜Œè¥ä¸šéƒ¨': ('C', 'æµ™æ±Ÿçœ,ç»å…´å¸‚,æ–°æ˜Œå¿'),
                    'è¡¢å·è¥ä¸šéƒ¨': ('Q', 'æµ™æ±Ÿçœ,è¡¢å·å¸‚,è¡¢æ±ŸåŒº')
                    }
    # df['é¦–å­—æ¯'] = df['å‘è¿å•å·'].str[0]
    for i in base_address.keys():
        df.loc[(df['å…¬å¸'] == i)  & (df['ä¸šåŠ¡ç±»å‹'] == 'äº§å“å‘è´§æ•´è½¦ä¸šåŠ¡') & (
            df['å‘è´§åœ°ç‚¹'].isnull()), 'å‘è´§åœ°ç‚¹'] = base_address[i][1]
        # df.loc[(df['å…¬å¸'] == i) & (df['é¦–å­—æ¯']==base_address[i][0])&(df['ä¸šåŠ¡ç±»å‹']=='äº§å“å‘è´§æ•´è½¦ä¸šåŠ¡')&(df['å‘è´§åœ°ç‚¹'].isnull()), 'å‘è´§åœ°ç‚¹'] = base_address[i][1]
        df.loc[df['å‘è´§åœ°ç‚¹'].str.contains('ä¸‹æ²™åŸºåœ°'),'å‘è´§åœ°ç‚¹'] ='æµ™æ±Ÿçœæ­å·å¸‚é’±å¡˜åŒºä¸‹æ²™'
        df.loc[df['åˆ°è´§åœ°ç‚¹'].str.contains('ä¸‹æ²™åŸºåœ°'), 'åˆ°è´§åœ°ç‚¹'] = 'æµ™æ±Ÿçœæ­å·å¸‚é’±å¡˜åŒºä¸‹æ²™'
    return df


#ğŸ‘†ğŸ‘†ğŸ‘†ğŸ‘†ğŸ‘†ğŸ‘†ğŸ‘†ğŸ‘†ğŸ‘†ğŸ‘†ğŸ‘†ğŸ‘†åŸºç¡€

#ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡è¡ç”Ÿ

def start(df):
    base_address = {'å¹¿ä¸œè¥ä¸šéƒ¨': ('Y', 'å¹¿ä¸œçœ,èŒ‚åå¸‚,é«˜å·å¸‚'),
                    'ç¦å»ºè¥ä¸šéƒ¨': ('M', 'ç¦å»ºçœ,æ¼³å·å¸‚,æ¼³æµ¦å¿'),
                    'å‰æ—è¥ä¸šéƒ¨': ('L', 'å‰æ—çœ,é•¿æ˜¥å¸‚,ä¹å°åŒº'),
                    'æ–°ç–†è¥ä¸šéƒ¨': ('J', 'æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº,ä¹Œé²æœ¨é½å¸‚,æ²™ä¾å·´å…‹åŒº'),
                    'å››å·è¥ä¸šéƒ¨': ('D', 'å››å·çœ,æˆéƒ½å¸‚,é¾™æ³‰é©¿åŒº'),
                    'å¤©æ´¥è¥ä¸šéƒ¨': ('T', 'å¤©æ´¥å¸‚,å¤©æ´¥å¸‚,æ»¨æµ·æ–°åŒº'),
                    'æ¹–å—è¥ä¸šéƒ¨': ('H', 'æ¹–å—çœ,é•¿æ²™å¸‚,å®ä¹¡å¸‚'),
                    'å…­å®‰è¥ä¸šéƒ¨': ('W', 'å®‰å¾½çœ,å…­å®‰å¸‚,é‡‘å®‰åŒº'),
                    'ä¸‹æ²™è¥ä¸šéƒ¨': ('S', 'æµ™æ±Ÿçœ,æ­å·å¸‚,é’±å¡˜åŒº'),
                    'è¥¿å®‰è¥ä¸šéƒ¨': ('A', 'é™•è¥¿çœ,è¥¿å®‰å¸‚,é›å¡”åŒº'),
                    'æ–°æ˜Œè¥ä¸šéƒ¨': ('C', 'æµ™æ±Ÿçœ,ç»å…´å¸‚,æ–°æ˜Œå¿'),
                    'è¡¢å·è¥ä¸šéƒ¨': ('Q', 'æµ™æ±Ÿçœ,è¡¢å·å¸‚,è¡¢æ±ŸåŒº'),
                    'æ²³å—åˆ†éƒ¨': ('H', 'æ²³å—çœ,ç„¦ä½œå¸‚,æ¸©å¿')
                    }
    df['é¦–å­—æ¯'] = df['å‘è¿å•å·'].str[0]
    df['å‘è´§åœ°ç‚¹'] = df['å‘è´§åœ°ç‚¹'].replace(' ','/')
    for i in base_address.keys():
        df.loc[(df['å…¬å¸'] == i) &(df['ä¸šåŠ¡ç±»å‹']=='äº§å“å‘è´§æ•´è½¦ä¸šåŠ¡')&(df['å‘è´§åœ°ç‚¹']=='/')&(~df['å‘è¿å•å·'].str.contains('CCD')), 'å‘è´§åœ°ç‚¹'] = base_address[i][1]
    df = df[df['ä¸šåŠ¡ç±»å‹'].isin([
                                'äº§å“å‘è´§æ•´è½¦ä¸šåŠ¡',
                                'å…¬è·¯æ•´è½¦-å…¶ä»–è´§ç‰©æ•´è½¦ä¸šåŠ¡',
                                'å›½é™…è´§ä»£ï¼ˆç¾å…ƒï¼‰-å‡ºå£',
                                'å…¬è·¯æ•´è½¦-äº§å“å‘è´§æ•´è½¦ä¸šåŠ¡',
                                'å›½é™…è´§ä»£ï¼ˆäººæ°‘å¸ï¼‰-å‡ºå£',
                                'å›½é™…è´§ä»£ï¼ˆäººæ°‘å¸ï¼‰-è¿›å£',
                                ])]
    df_out = company_out(r'E:\MK\æ•°æ®æº\æ¯›åˆ©æŠ¥è¡¨-å†…éƒ¨')
    df_out['å®¢æˆ·ç±»å‹'] = 'å†…éƒ¨å®¢æˆ·'
    df = pd.merge(df,df_out,on='å®¢æˆ·',how='left')
    df['å®¢æˆ·ç±»å‹'] = df['å®¢æˆ·ç±»å‹'].fillna('å¤–éƒ¨å®¢æˆ·')
    return df

def company_out(path_out):
    df = MYB_read_and_concatenate(path_out)
    df = df[['å®¢æˆ·']].drop_duplicates()
    return df


def standardize_truck_size(size_str):
    size_str = size_str.replace("ç±³", "").strip()
    try:
        size = float(size_str)
    except ValueError:
        return "æœªçŸ¥"

    if size <= 5.5:
        return "4.2ç±³"
    elif size <= 8.2:
        return "6.8ç±³"
    elif size <= 11.1:
        return "9.6ç±³"
    elif size <= 15:
        return "12.5ç±³"
    elif size <= 20:
        return "17.5ç±³"
    else:
        return "æœªçŸ¥"

def standardize_truck_size_2(size_str):
    size_str0 = size_str
    size_str = size_str.replace("ç±³", "").strip()
    try:
        size = float(size_str)
    except ValueError:
        return "æœªçŸ¥"
    if size <= 8.2:
        return size_str0
    elif size <= 11.1:
        return "9.6ç±³"
    elif size <= 15:
        return "12.5ç±³"
    elif size <= 20:
        return "17.5ç±³"
    else:
        return "æœªçŸ¥"

def point_match(province,point,point_raw):
    if province=='/':
        return point_raw
    else:
        return point

def data_select():
    df_revenue = pd.read_sql('SELECT * FROM revenue_old WHERE é‡‡è´­ä»· > 50 AND ç»“ç®—ä»· > 10 AND ä¸šåŠ¡ç±»å‹ NOT LIKE "%%é›¶æ‹…%%"',con=engine_ccd)
    df_revenue = start(df_revenue)
    df_revenue = df_revenue[df_revenue['è½¦å‹'].notnull()]
    df_address = pd.read_sql('SELECT * FROM revenue_address',con=engine_ccd)
    df_address = df_address.drop_duplicates('point')
    df_car = pd.read_sql('SELECT å‘è¿å•å·, æ‰¿è¿å•†, å¸è´§ç‚¹æ•°, æŒ‡å¯¼ä»·, ç»“ç®—ç‚¹, çœ, å¸‚, å¿åŒº, å¤–éƒ¨å•å· FROM car',con=engine_ccd)
    df_car['çœå¸‚å¿'] = df_car['çœ'] + df_car['å¸‚'] + df_car['å¿åŒº']
    df_revenue = pd.merge(df_revenue, df_car, on='å‘è¿å•å·', how='left')
    df_revenue = df_revenue.fillna('/')
    df_revenue = df_revenue.replace(' ','/')
    df_revenue['point_match'] = df_revenue.apply(lambda x:point_match(x['çœ'],x['çœå¸‚å¿'],x['åˆ°è´§åœ°ç‚¹']),axis=1)
    df_revenue = pd.merge(df_revenue,df_address,left_on='å‘è´§åœ°ç‚¹',right_on='point',how='left')
    df_revenue = pd.merge(df_revenue,df_address,left_on='point_match',right_on='point',how='left')
    df_revenue['routine_all'] = df_revenue['longitude_x'] + ',' + df_revenue['latitude_x'] + ';' + df_revenue['latitude_y'] + ',' + \
                             df_revenue['longitude_y']
    df_cheapest = pd.read_sql('SELECT * FROM routine_distance_cheapest', con=engine_ccd)
    df_cheapest['routine_all'] = df_cheapest['longitude_x'] + ',' + df_cheapest['latitude_x'] + ';' + df_cheapest[
        'latitude_y'] + ',' + df_cheapest['longitude_y']
    df_cheapest = df_cheapest.drop_duplicates(['routine_all'])
    df_cheapest = df_cheapest[['routine_all','distance','duration']]
    df_cheapest['distance'] = df_cheapest['distance'].astype(float).fillna(-1)
    df_cheapest['distance'] = df_cheapest['distance']/1000
    df_revenue = pd.merge(df_revenue,df_cheapest,on='routine_all',how='left')
    df_revenue['çº¿è·¯'] = df_revenue['point_standard_x'] + '-' + df_revenue['point_standard_y']
    df_revenue['ä¸šåŠ¡æ—¥æœŸ'] = pd.to_datetime(df_revenue['ä¸šåŠ¡æ—¥æœŸ'],format='%Y%m%d')
    df_revenue['å¹´'] = df_revenue['ä¸šåŠ¡æ—¥æœŸ'].dt.year
    df_revenue['æœˆ'] = df_revenue['ä¸šåŠ¡æ—¥æœŸ'].dt.month
    df_revenue['æ ‡å‡†åŒ–è½¦å‹'] = df_revenue.apply(lambda x:standardize_truck_size(x['è½¦å‹']),axis=1)
    # df_agg = df_revenue.groupby(['å…¬å¸','çº¿è·¯','å¹´','æ ‡å‡†åŒ–è½¦å‹']).agg(é‡‡è´­å‡ä»·=('é‡‡è´­ä»·','mean'),è½¦æ¬¡=('å‘è¿å•å·','count')).reset_index()
    # print(df_agg)
    return df_revenue

def data_select_raw_start():
    df_revenue = pd.read_sql('SELECT å‘è´§åœ°ç‚¹, åˆ°è´§åœ°ç‚¹, å‘è¿å•å·, å…¬å¸, ä¸šåŠ¡ç±»å‹, å®¢æˆ·, è½¦å‹, ä¸šåŠ¡æ—¥æœŸ, å¤‡æ³¨ FROM revenue_old WHERE é‡‡è´­ä»· > 50 AND ç»“ç®—ä»· > 10 AND ä¸šåŠ¡ç±»å‹ NOT LIKE "%%é›¶æ‹…%%" AND ä¸šåŠ¡ç±»å‹ NOT LIKE "%%åˆ°ä»˜%%" AND ä¸šåŠ¡ç±»å‹ NOT LIKE "%%æ‰«ç ä»˜%%" AND ä¸šåŠ¡ç±»å‹ NOT LIKE "%%è°ƒæ•´%%"',con=engine_ccd)
    df_revenue = start(df_revenue)
    df_revenue = df_revenue[df_revenue['è½¦å‹'].notnull()]
    df_address = pd.read_sql('SELECT * FROM revenue_address',con=engine_ccd)
    df_address = df_address.drop_duplicates('point')
    df_car = pd.read_sql('SELECT å‘è¿å•å·, æˆæœ¬æ€»é‡‘é¢, æ‰¿æ‹…è¿è´¹, æ‰¿æ‹…è¿è´¹ç±»å‹, å¸è´§ç‚¹æ•°, æŒ‡å¯¼ä»·, ç»“ç®—ç‚¹, çœ, å¸‚, å¿åŒº, å¤–éƒ¨å•å· FROM car',con=engine_ccd)
    df_car['çœå¸‚å¿'] = df_car['çœ'] + df_car['å¸‚'] + df_car['å¿åŒº']
    df_car['é‡‡è´­ä»·'] = df_car['æˆæœ¬æ€»é‡‘é¢']
    df_car.loc[df_car['æ‰¿æ‹…è¿è´¹ç±»å‹']=='æ‰¿æ‹…è¿è´¹ç°ç»“','é‡‡è´­ä»·'] = df_car.loc[df_car['æ‰¿æ‹…è¿è´¹ç±»å‹']=='æ‰¿æ‹…è¿è´¹ç°ç»“','æˆæœ¬æ€»é‡‘é¢'] + df_car.loc[df_car['æ‰¿æ‹…è¿è´¹ç±»å‹']=='æ‰¿æ‹…è¿è´¹ç°ç»“','æ‰¿æ‹…è¿è´¹']
    df_revenue = pd.merge(df_revenue, df_car, on='å‘è¿å•å·', how='left')
    df_revenue = df_revenue.fillna('/')
    df_revenue = df_revenue.replace(' ','/')
    # df_revenue['point_match'] = df_revenue.apply(lambda x:point_match(x['çœ'],x['çœå¸‚å¿'],x['åˆ°è´§åœ°ç‚¹']),axis=1)
    df_revenue = pd.merge(df_revenue,df_address,left_on='å‘è´§åœ°ç‚¹',right_on='point',how='left')
    df_revenue = pd.merge(df_revenue,df_address,left_on='åˆ°è´§åœ°ç‚¹',right_on='point',how='left')
    df_revenue['çº¿è·¯'] = df_revenue['point_standard_x'] + '-' + df_revenue['point_standard_y']
    df_revenue['ä¸šåŠ¡æ—¥æœŸ'] = pd.to_datetime(df_revenue['ä¸šåŠ¡æ—¥æœŸ'],format='%Y%m%d')
    df_revenue['å¹´'] = df_revenue['ä¸šåŠ¡æ—¥æœŸ'].dt.year
    df_revenue['æœˆ'] = df_revenue['ä¸šåŠ¡æ—¥æœŸ'].dt.month
    df_revenue['æ ‡å‡†åŒ–è½¦å‹'] = df_revenue.apply(lambda x:standardize_truck_size(x['è½¦å‹']),axis=1)
    # df_agg = df_revenue.groupby(['å…¬å¸','çº¿è·¯','å¹´','æ ‡å‡†åŒ–è½¦å‹']).agg(é‡‡è´­å‡ä»·=('é‡‡è´­ä»·','mean'),è½¦æ¬¡=('å‘è¿å•å·','count')).reset_index()
    # print(df_agg)
    return df_revenue

def full_to_half(text):
    """
    å°†å…¨è§’å­—ç¬¦è½¬æ¢ä¸ºåŠè§’å­—ç¬¦
    :param text: åŒ…å«å…¨è§’å­—ç¬¦çš„å­—ç¬¦ä¸²
    :return: è½¬æ¢åçš„åŠè§’å­—ç¬¦ä¸²
    """
    if not isinstance(text, str):
        return text  # éå­—ç¬¦ä¸²ç±»å‹ç›´æ¥è¿”å›

    result = []

    for char in text:
        # è·å–å­—ç¬¦çš„Unicodeç¼–ç 
        code = ord(char)
        # å…¨è§’ç©ºæ ¼è½¬æ¢ä¸ºåŠè§’ç©ºæ ¼
        if not char:
            return text
        if code == 0x3000:
            result.append(chr(0x20))
        # å…¨è§’å­—ç¬¦ï¼ˆé™¤ç©ºæ ¼å¤–ï¼‰è½¬æ¢ä¸ºåŠè§’
        elif 0xFF01 <= code <= 0xFF5E:
            result.append(chr(code - 0xFEE0))
        # å…¶ä»–å­—ç¬¦ä¸è½¬æ¢
        else:
            result.append(char)
    print('å·²æ›¿æ¢æˆåŠè§’')
    return ''.join(result)